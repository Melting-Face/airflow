---
version: "3.7"
services:
  airflow:
    container_name: airflow
    build: airflow
    ports:
      - "8080:8080"
    command: ["standalone"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__CORE__TEST_CONNECTION=Enabled
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://dbt:dbt@db:5432/metastore
      - SPARK_HOST=spark
    depends_on:
      - db
  spark:
    container_name: spark
    build: spark
    ports:
      - "10000:10000"
      - "4040:4040"
    user: '0'
    command:
      - |
        /opt/spark/bin/spark-shell \
        --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 \
        --name "Thrift JDBC/ODBC Server"
    entrypoint: ["bash", "-c"]
    depends_on:
      - metastore
  db:
    container_name: db
    image: postgres:14
    ports:
      - "25432:5432"
    volumes:
      - ./metastore:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=dbt
      - POSTGRES_PASSWORD=dbt
      - POSTGRES_DB=metastore
  minio:
    container_name: minio
    build: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data:/data
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=admin1234
  metastore:
    container_name: metastore
    build: hive
    ports:
      - "9083:9083"
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
    depends_on:
      - db
      - minio
  trino:
    container_name: trino
    image: trinodb/trino
    ports:
      - "18080:8080"
    volumes:
      - ./catalog:/etc/trino/catalog
    depends_on:
      - metastore
  superset:
    container_name: superset
    build: superset
    ports:
      - "8088:8088"
    environment:
      - SUPERSET_SECRET_KEY=c2VjcmV0X2tleQ==
      - WTF_CSRF_ENABLED='False'
      - TALISMAN_ENABLED='False'
    platform: linux/amd64
    command: ["sh", "create_user.sh"]
