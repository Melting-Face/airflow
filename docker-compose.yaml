---
version: "3.7"
services:
  dbt-spark:
    container_name: dbt-spark
    image: apache/spark-py:v3.4.0
    ports:
      - "10000:10000"
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    user: '0'
    command:
      - |
        /opt/spark/bin/spark-shell \
        --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 \
        --packages "io.delta:delta-core_2.12:2.4.0" \
        --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" \
        --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"
    entrypoint: ["bash", "-c"]
    deploy:
      resources:
        limits:
          memory: 4g
    volumes:
      - ./logs:/opt/spark/log
      - ./conf:/opt/spark/conf
      - ./jars/postgresql-42.3.8.jar:/opt/spark/jars/postgresql-42.3.8.jar
    depends_on:
      - dbt-metastore

  dbt-metastore:
    container_name: dbt-metastore
    image: postgres:14
    ports:
      - "25432:5432"
    volumes:
      - ./.data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=dbt
      - POSTGRES_PASSWORD=dbt
      - POSTGRES_DB=metastore
